#!/usr/bin/env python3

import os
import sys

# ROS
import rospy
import numpy as np
import math

# import time
import statistics
import cv2
from cv_bridge import CvBridge, CvBridgeError
from yolox.exp import get_exp
from clf_object_recognition_yolox import recognizer

########
import message_filters
from sensor_msgs.msg import Image, CameraInfo

########
import std_msgs.msg
from geometry_msgs.msg import PoseArray, Pose
from people_msgs.msg import People, Person
from image_geometry import cameramodels


class YoloxPeopleNode:
    def __init__(
        self,
        checkpoint,
        exp_path,
        config,
        camera_info_path="/xtion/depth_registered/camera_info",
        image_path="/xtion/rgb/image_raw",
        depth_path="/xtion/depth_registered/image_raw",
        classid=0,
        depth_scaling=1,
        variance_scaling=10,
    ):
        rospy.loginfo(logger_name="YoloxPeopleNode", msg="initializing:")
        rospy.loginfo(logger_name="YoloxPeopleNode", msg=f" - checkpoint={checkpoint}")
        rospy.loginfo(logger_name="YoloxPeopleNode", msg=f" - exp_path={exp_path}")
        self.pub = rospy.Publisher("~poses", PoseArray, queue_size=1)
        self.pub_people = rospy.Publisher("~people", People, queue_size=1)
        self.classid = classid
        self.depth_scaling = depth_scaling

        self.exp = get_exp(exp_path, "")
        if "conf" in config:
            self.exp.test_conf = config["conf"]

        self.recognizer = recognizer.Recognizer(checkpoint, self.exp)

        self._bridge = CvBridge()
        image_sub = message_filters.Subscriber(image_path, Image)
        info_sub = message_filters.Subscriber(camera_info_path, CameraInfo)
        depth_sub = message_filters.Subscriber(depth_path, Image)
        self.ts = message_filters.ApproximateTimeSynchronizer(
            [image_sub, info_sub, depth_sub], 1, 1
        )
        self.ts.registerCallback(self.callback)

        self.camera = cameramodels.PinholeCameraModel()

    def callback(self, image, camera_info, depth_raw):
        variance_scaling = 10  # muss noch in den methodenkopf
        # print("got images")
        try:
            img = self._bridge.imgmsg_to_cv2(image, "bgr8")
            depth = self._bridge.imgmsg_to_cv2(depth_raw, "passthrough")
            if depth.dtype == np.float32:
                self.depth_scaling = 1
            elif depth.dtype == np.uint16:
                self.depth_scaling = 0.001
            else:
                self.depth_scaling = 1
        except CvBridgeError as e:
            error_msg = "Could not convert to opencv image: %s" % e
            rospy.logerr(logger_name="YoloxPeopleNode", msg=error_msg)
            raise Exception(error_msg)
        (cls, scores, bboxes) = self.recognizer.inference(img)

        self.camera.fromCameraInfo(camera_info)
        constant_y = self.depth_scaling / self.camera.fy()
        constant_x = self.depth_scaling / self.camera.fx()

        msg = PoseArray()
        msg_people = People()
        msg.header = image.header
        msg_people.header = image.header
        for c, score, box in zip(cls, scores, bboxes):
            # zeitanfang = time.time()
            if c == self.classid and score > 0.5:
                h = box[3] - box[1]
                w = box[2] - box[0]
                yc = ((box[1] + box[3]) / 2).item()
                xc = ((box[0] + box[2]) / 2).item()
                # direction for the pointcross
                height_direction = 1
                wide_direction = 1
                h_area = h // variance_scaling
                w_area = w // variance_scaling
                if h_area < 2:
                    h_area = 2
                if w_area < 2:
                    w_area = 2
                mean_circle_depth_list = []
                z = (depth[int(yc)][int(xc)]) * self.depth_scaling
                if not ((z == 0) or (np.isnan(z))):
                    x = (xc - self.camera.cx()) * (depth[int(yc)][int(xc)]) * constant_x
                    y = (yc - self.camera.cy()) * (depth[int(yc)][int(xc)]) * constant_y
                    dis = math.sqrt((x**2) + (y**2) + (z**2))
                    mean_circle_depth_list.append([x, y, z, dis])
                # count=4#how many points should be generated
                for i in range(4):
                    if i % 2 == 0:  # even height
                        xd = xc
                        yd = (yc + (np.random.randint(1, h_area))) * height_direction
                        height_direction = height_direction * -1
                    else:  # odd wide
                        xd = (xc + (np.random.randint(1, w_area))) * wide_direction
                        yd = yc
                        wide_direction = wide_direction * -1
                    z = (depth[int(yd)][int(xd)]) * self.depth_scaling
                    if not ((z == 0) or (np.isnan(z))):
                        x = (
                            (xd - self.camera.cx())
                            * (depth[int(yd)][int(xd)])
                            * constant_x
                        )
                        y = (
                            (yd - self.camera.cy())
                            * (depth[int(yd)][int(xd)])
                            * constant_y
                        )
                        dis = math.sqrt((x**2) + (y**2) + (z**2))
                        mean_circle_depth_list.append([x, y, z, dis])
                    # if (np.isnan(z)):
                    # 	print("dead end")
                # mean_circle_depth=np.median(mean_circle_depth_list.T[3])
                # mean_circle_depth=np.mean(mean_circle_depth_list.T[3])
                # remove the outlier if there is one
                # while(abs(np.min(mean_circle_depth_list.T[3])-mean_circle_depth)>1 or abs(np.max(mean_circle_depth_list.T[3])-mean_circle_depth)>1):
                # for i in range(int((abs(np.min(mean_circle_depth_list.T[3])-mean_circle_depth)-1+abs(np.max(mean_circle_depth_list.T[3])-mean_circle_depth)-1)/2)):
                # 	argmin=np.argmin(mean_circle_depth_list.T[3])
                # 	argmax=np.argmax(mean_circle_depth_list.T[3])
                # 	if not (int(mean_circle_depth_list[argmin,3])==int(mean_circle_depth_list[argmax,3])): #check if there are near to each other
                # 		depthmin=math.fabs(mean_circle_depth_list[argmin,3])
                # 		depthmax= math.fabs(mean_circle_depth_list[argmax,3])
                # 		if(depthmin<depthmax):
                # 			mean_circle_depth_list=np.delete(mean_circle_depth_list, argmax, 0)
                # 		elif(depthmin>depthmax):
                # 			mean_circle_depth_list=np.delete(mean_circle_depth_list, argmin, 0)
                # 		else:
                # 			if dislist.size>2:
                # 				mean_circle_depth_list=np.delete(mean_circle_depth_list, argmin, 0)
                # 				mean_circle_depth_list=np.delete(mean_circle_depth_list, argmax, 0)
                # 			else:
                # 				break
                # 		mean_circle_depth=np.mean(mean_circle_depth_list.T[3])

                # 	else:
                # 		print("problem", (mean_circle_depth_list[argmin]), (mean_circle_depth_list[argmax]))
                # 		break
                mean_circle_depth_list = np.array(mean_circle_depth_list)
                try:
                    if ((mean_circle_depth_list.size)) >= 4:
                        idx = (
                            np.abs(
                                mean_circle_depth_list.T[3]
                                - statistics.median(mean_circle_depth_list.T[3])
                            )
                        ).argmin()
                        rospy.logdebug(
                            logger_name="YoloxPeopleNode",
                            msg=f"human: {mean_circle_depth_list[idx][1]}, {mean_circle_depth_list[idx][0]}, {mean_circle_depth_list[idx][2]}",
                        )
                        pose = Pose()
                        pose.position.x = mean_circle_depth_list[idx][0]
                        pose.position.y = mean_circle_depth_list[idx][1]
                        pose.position.z = mean_circle_depth_list[idx][2]
                        pose.orientation.w = 1
                        person = Person()
                        person.reliability = score
                        person.position.x = mean_circle_depth_list[idx][0]
                        person.position.y = mean_circle_depth_list[idx][1]
                        person.position.z = mean_circle_depth_list[idx][2]
                        person.orientation.w = 1
                        if not (pose.position.z == 0):
                            msg.poses.append(pose)
                            msg_people.people.append(person)
                except:
                    print("Warning:", mean_circle_depth_list)
        self.pub.publish(msg)
        self.pub_people(msg_people)


if __name__ == "__main__":

    # Start ROS node
    rospy.init_node("yolox_people_tracker")

    try:
        _checkpoint = os.path.expanduser(rospy.get_param("~checkpoint"))
        _exp_path = os.path.expanduser(rospy.get_param("~exp"))
        _config = rospy.get_param("~")
        _camera_info = rospy.get_param("~camera_info")
        _img = rospy.get_param("~img")
        _depth = rospy.get_param("~depth")
        _cid = rospy.get_param("~classid")
        _depth_scaling = rospy.get_param("~depth_scaling")
        # _variance_scaling = 10#rospy.get_param("~variance_scaling")
    except KeyError as e:
        rospy.logerr(logger_name="YoloxPeopleNode", msg="Parameter %s not found" % e)
        sys.exit(1)

    node = YoloxPeopleNode(
        _checkpoint,
        _exp_path,
        _config,
        _camera_info,
        _img,
        _depth,
        _cid,
        _depth_scaling,
        10,
    )

    rospy.loginfo(logger_name="YoloxPeopleNode", msg="\nyolox person detection running")

    rospy.spin()
